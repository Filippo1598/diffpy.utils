#!/usr/bin/env python
##############################################################################
#
# diffpy.utils      by DANSE Diffraction group
#                   Simon J. L. Billinge
#                   (c) 2010 The Trustees of Columbia University
#                   in the City of New York.  All rights reserved.
#
# File coded by:
#
# See AUTHORS.txt for a list of people who contributed.
# See LICENSE_DANSE.txt for license information.
#
##############################################################################

import pathlib
import json

# FIXME: add support for yaml, xml
supported_formats = ['.json']


def serialize_data(filename, hdata: dict, data_table: list, show_path=True, dt_colnames=None, serial_file=None):
    """Serialize file data into a dictionary. Can also save dictionary into a serial language file.
    Dictionary is formatted as {filename: data}.

    Requires hdata and data_table generated from loadData.

    filename        -- name of the file whose data is being serialized.
    hdata          -- Dictionary of PDF metadata generated by loadData.
    data_table      -- List storing  parsed by loadData.
    dt_colnames     -- List containing names of each column in data_table. Every name in
                       data_table_cols will be put into the Dictionary as a key with a value
                       of that column in data_table (stored as a List). Put None for
                       columns without names. If dt_cols has less non-None entries
                       than columns in data_table, the pair {'data table': data_table} will be put
                       in the dictionary. (Default None: only entry {'data table': data_table}
                       will be added to dictionary.)
    show_path       -- include a path element in the database entry (default True).
                       If 'path' is not included in hddata, extract path from filename.
    serial_file     -- serial language file to dump dictionary into.

    Returns the dictionary loaded from/into the updated database file.
    """

    # compile data_table and hddata together
    data = {}

    # handle getting name of file for variety of filename types
    with open(filename, 'r') as file_path:
        abs_path = pathlib.Path(file_path.name).resolve()
        # add path to start of data if requested
        if show_path and 'path' not in hdata.keys():
            data.update({'path': abs_path.name})
        # title the entry with name of file (taken from end of path)
        title = abs_path.name

    # first add named columns in dt_cols
    num_columns = [len(row) for row in data_table]
    max_columns = max(num_columns)
    num_col_names = len(dt_colnames)
    if max_columns < num_col_names:  # assume numpy.loadtxt gives non-irregular array
        raise Exception("More entries in dt_colnames than columns in data_table.")
    named_columns = 0
    for idx in range(num_col_names):
        colname = dt_colnames[idx]
        if colname is not None:
            data.update({colname: list(data_table[:, idx])})
            named_columns += 1

    # second add data in hddata dict
    data.update(hdata)

    # finally add data_table as an entry named 'data table' if not all columns were parsed
    if named_columns < max_columns:
        if 'data table' not in data.keys():
            data.update({'data table': data_table})
        else:  # if 'data table' is already a key, keep adding primes to the end
            dt_name = 'data table'
            while dt_name in data.keys():
                dt_name += " prime"
            data.update({dt_name: data_table})

    # parse name using pathlib and generate dictionary entry
    entry = {title: data}

    # no save
    if serial_file is None:
        return entry

    # saving/updating file
    # check if supported type
    extension = pathlib.Path(serial_file).suffix
    if extension not in supported_formats:
        raise Exception(f"Format of {serial_file} is not supported.")

    # new file or update
    existing = False
    try:
        open(serial_file)
        existing = True
    except FileNotFoundError:
        pass

    # json
    if extension == '.json':
        # dump if non-existing
        if not existing:
            with open(serial_file, 'w') as jsonfile:
                file_data = entry  # for return
                json.dump(file_data, jsonfile, indent=2)

        # update if existing
        else:
            with open(serial_file, 'r') as json_read:
                file_data = json.load(json_read)
                file_data.update(entry)
            with open(serial_file, 'w') as json_write:
                # dump to string first for formatting
                json.dump(file_data, json_write, indent=2)

    return file_data


def deserialize_data(filename):
    """Load a dictionary from a serial file.

    filename    -- database file to load from.

    Returns a dictionary of database information.
    """

    # check if supported type
    extension = pathlib.Path(filename).suffix
    if extension not in supported_formats:
        raise Exception(f"Format of {filename} is not supported.")

    # json
    if extension == '.json':
        with open(filename, 'r') as json_file:
            j_dict = json.load(json_file)

    return j_dict


def serial_oneline(filename):
    """Reformat lists in markup languages to take up only one line.

    Works well when only lists are surrounded by square brackets and no other data is comma and newline separated.

    filename    -- name of markup file to reformat.
    """

    # check file type
    extension = pathlib.Path(filename).suffix
    if extension not in supported_formats:
        raise Exception(f"Format of {filename} is not supported.")

    if extension == '.json':
        # cannot easily do regex substitution since lists are of floats
        with open(filename, 'r+') as json_file:
            lines = json_file.readlines()
            json_file.seek(0)
            json_file.truncate()

            s_flag = False
            for line in lines:
                if "\"r\": [" in line or "\"gr\": [" in line:
                    s_flag = True
                    updated_line = line[:-1]
                elif "]," in line:
                    s_flag = False
                    updated_line = f"{updated_line[:-1]}{line.strip()}\n"
                    json_file.write(updated_line)
                elif s_flag:
                    updated_line += f"{line[:-1].strip()} "
                else:
                    json_file.write(line)


def apply_schema_to_file(filename, schemaname, multiple_entries=False):
    """ Reformat a file so relevant entries match the same order as a schema file.
    Other entries are put at the end in the same order.

    filename            -- name of file to apply the schema to.
    schemaname          -- name of schema to apply.
    multiple_entries    -- True if database file (i.e. those generated by load_PDF_into_db).
                           False if data from a single file (i.e. those generated by markup_PDF).

    Returns the dictionary loaded from/into the reformatted file.
    """

    # ensure proper extension
    file_ext = pathlib.Path(filename).suffix
    schema_ext = pathlib.Path(schemaname).suffix
    if file_ext != schema_ext:
        return Exception("Schema type does not match file type.")
    if file_ext not in supported_formats:
        return Exception(f"Format of {filename} is not supported.")

    # json
    if file_ext == ".json":
        with open(schemaname, 'r') as jsonschema:
            schema = json.load(jsonschema)
            schema_order = []
            for dp in schema:
                schema_order.append(dp)

        # database file
        if multiple_entries:
            # reformat each entry in a collection
            with open(filename, 'r') as json_read:
                data_dict = json.load(json_read)
                reformatted_dict = {}  # new dictionary for entire json
                for entry in data_dict.keys():
                    # reformat each entry
                    entry_dict = data_dict.get(entry)
                    reformatted_entry = {}  # new dictionary for a particular entry
                    for dp in schema_order:
                        if dp in entry_dict:
                            reformatted_entry.update({dp: entry_dict.get(dp)})
                            entry_dict.pop(dp)
                    reformatted_entry.update(entry_dict)
                    reformatted_dict.update({entry: reformatted_entry})
            with open(filename, 'w') as json_write:
                json.dump(reformatted_dict, json_write, indent=2)

        # single file
        else:
            with open(filename, 'r') as json_read:
                data_dict = json.load(json_read)
                reformatted_dict = {}
                # reformat
                for dp in schema_order:
                    if dp in data_dict:
                        reformatted_dict.update({dp: data_dict.get(dp)})
                        data_dict.pop(dp)
                reformatted_dict.update(data_dict)
            with open(filename, 'w') as json_write:
                json.dump(reformatted_dict, json_write, indent=2)

    return reformatted_dict
